---
title: "Questions on My Mind"
---

1. Can communication and debate improve outcomes in cooperative dilemmas among LLM agents?
2. Will cumulative cultural evolution be as important for advanced AI agents as it has been for humanity?
3. Are "thinking" inference-time models better equipped to solve cooperative dilemmas?
4. How big a role will selection (as opposed to e.g. design) play in shaping the trajectory of advanced AI? What will the selection pressures be?
5. How does the cultural evolution of AI behaviors interact with issues in AI safety and governance?
6. What are the cultural evolutionary implications of various proposed [agent infrastructure](https://arxiv.org/abs/2501.10114)?
